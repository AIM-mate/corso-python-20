{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myLz0ycsuMMY"
   },
   "source": [
    "#Web scraping del sito della collana di libri Adelphi \n",
    "Una delle task più comuni per cui viene impiegato Python è il così detto **web scraping**. Il web scraping consiste nell'automatizzare l'ottenimento di alcune informazioni dal web tramite un codice e di utilizzarle di conseguenza. La qualità e la semplicità nell'ottenimento delle informazioni è dato solitamente dalla struttura della fonte: alcuni siti sono molto più semplici da navigare mentre altri possono essere più complessi. Per questo motivo il web scraping è spesso molto complesso. \n",
    "In questo esercizio vi verrà fornito uno scraper già fatto in grado di ottenere informazioni dal catalogo online della nota collana di **libri Adelphi** (https://www.adelphi.it/): calandovi nei panni di un avido lettore e collezionista di libri, il vostro obiettivo sarà di utilizzarlo per digitalizzare interamente la vostra collezione di libri, in modo da poter velocemente controllare l'inventario dei vostri libri ed alcune informazioni a riguardo con un semplice comando ogni volta che lo vorrete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "executionInfo": {
     "elapsed": 6465,
     "status": "ok",
     "timestamp": 1602763937339,
     "user": {
      "displayName": "Corso Python",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhUJnZlNXXV-eAoMnBindJd9r8g8VQoai18e-XA=s64",
      "userId": "02320948615677398231"
     },
     "user_tz": -120
    },
    "id": "D_37H-lC7lK3",
    "outputId": "aaa4db14-6f1b-46a4-e8c1-0bc34f97463b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\valen\\anaconda3\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\valen\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\valen\\anaconda3\\lib\\site-packages (from requests) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\valen\\anaconda3\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\valen\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\valen\\anaconda3\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\valen\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANTE\n",
    "# questa cella di codice serve ad installare nel vostro Python due tra i principali strumenti di web scraping: beautiful soup e requests.\n",
    "# qualora di fossero problemi con la loro installazione o import non esitate a contattarci\n",
    "!pip install requests\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DucKAxg-6g50"
   },
   "source": [
    "# Implementazione dello scraper\n",
    "Come anticipato, non vi sarà richiesto di implementare lo scraper. Tuttavia gli interessati possono trovare informazioni su come utilizzare al meglio le due librerie per lo scraping *requests* e *beautifulsoup* e cercare di comprendere il codice della classe AdelphiScraper. Se non siete tra questi potete saltare alla prossima sezione.\n",
    "Qui qualche risorsa:\n",
    "\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "https://requests.readthedocs.io/en/master/user/quickstart/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Gr5uChnzMN4a"
   },
   "outputs": [],
   "source": [
    "import requests as req\n",
    "import bs4 as bs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "zUZulxHc7smv"
   },
   "outputs": [],
   "source": [
    "class AdelphiScraper():\n",
    "  def __init__(self):\n",
    "    self.catalog      = 'https://www.adelphi.it/catalogo/'\n",
    "    self.subject      = 'https://www.adelphi.it/catalogo/materia/'\n",
    "    self.subjects_map = self.init_subjects()\n",
    "\n",
    "  def init_subjects(self):\n",
    "    resp  = req.get(self.catalog)\n",
    "    soup  = bs.BeautifulSoup(resp.text, \"html.parser\")\n",
    "    items = soup.find_all('ul', class_='subject')\n",
    "    ret = dict()\n",
    "    for i in items:\n",
    "      for j in i:\n",
    "        ret.update({int(j.a['href'].split('/')[-1]) : j.text})\n",
    "    return ret\n",
    "\n",
    "  def get_subject_list(self):\n",
    "    return self.subjects_map\n",
    "  \n",
    "  def get_subject_books(self, subject_code):\n",
    "    page_found = True\n",
    "    suffix = ''\n",
    "    page_counter = 1\n",
    "    books = dict()\n",
    "    isbns = dict()\n",
    "    while page_found:\n",
    "      try:\n",
    "        resp = req.get(self.subject + str(subject_code) + suffix, allow_redirects = False)\n",
    "        soup = bs.BeautifulSoup(resp.text, \"html.parser\")\n",
    "        if not len(soup):\n",
    "          raise ValueError()\n",
    "        book_infos, isbn_maps = self.extract_books(soup)\n",
    "        books.update(book_infos)\n",
    "        isbns.update(isbn_maps)\n",
    "        page_counter += 1\n",
    "        suffix = '/p' + str(page_counter)\n",
    "      except:\n",
    "        page_found = False\n",
    "    return books, isbns\n",
    "\n",
    "  def extract_books(self, soup):\n",
    "    items = soup.find_all('div', class_='list_impressum')\n",
    "    items2 = soup.find_all('div', class_='data' )\n",
    "    items3 = soup.find_all('div', class_ = \"abstract hidden-xs\")\n",
    "    isbn_map  = dict()\n",
    "    book_info = dict()\n",
    "    counter = 0\n",
    "    for i in items:\n",
    "      isbn_map.update({i.a['href'].split('/')[-1] : i.a.text}) #isbn : titolo\n",
    "      book_info.update({i.a.text : {'Autore': i.div.text, \\\n",
    "                                    'Anno': items2[counter].text.split(' ')[0].split(',')[0], \\\n",
    "                                    'Prezzo Originale' : i.span.text.split(' ')[1].replace(',','.'), \\\n",
    "                                    'Sconto': i.span.text.split(' ')[2], \\\n",
    "                                    'Pagine' :items2[counter].text.split(' ')[2].split(',')[0].split('-')[-1], \\\n",
    "                                    'Abstract': items3[counter].text}})\n",
    "      counter += 1\n",
    "    return book_info, isbn_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwoSPBLFkHDm"
   },
   "source": [
    "#Utilizzo della classe AdelphiScraper\n",
    "\n",
    "*   La classe AdelphiScraper non richiede alcun argomento di inizializzazione.\n",
    "*   Essendo un WebScraper richiede ovviamente la connessione ad internet.\n",
    "*   Essa contiene al suo interno diversi attributi e metodi, i metodi che vi serviranno sono:\n",
    "    * `get_subject_list()` : questo metodo restituisce un dizionario contenente tutte le categorie della collana di libri Adelphi e il codice numerico a cui sono associate sul sito.\n",
    "    * `get_subject_books(category_code)` : questo metodo riceve il codice numerico (**come intero**) di una categoria e restituisce due dizionari: \n",
    "        * Il primo ha come chiave i titoli dei libri appartenenti alla categoria e come valori svariati dati ad essi inerenti (Autore, prezzo, anno di stampa dell'ultima edizione, etc.)\n",
    "        * Il secondo ha come chiavi gli ISBN (codice univoco diverso da libro a libro) e come valori i titoli dei libri associati.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "TJl4Yq15njPs"
   },
   "outputs": [],
   "source": [
    "## Come prima cosa istanziate un oggetto di classe AdelphiScraper e provate ad utilizzare i due metodi sopra descritti per osservarne l'output,\n",
    "## questa operazione è molto importante al fine di capire bene quali sono le strutture dati a vostra dispozione.\n",
    "## ATTENZIONE : osservate bene quali sono i tipi dei dati contenuti nelle strutture che riceverete in output, più avanti avrete bisogno di farvi operazioni o conversioni.\n",
    "\n",
    "Ad_Scraper = AdelphiScraper()\n",
    "\n",
    "diz_subject = Ad_Scraper.get_subject_list()\n",
    "\n",
    "diz_books = Ad_Scraper.get_subject_books(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_from_ISBN(ISBN): #LENTISSIMO, non saprei come velocizzarlo\n",
    "    for i in range(1,max(Ad_Scraper.get_subject_list())):\n",
    "        diz_temp = Ad_Scraper.get_subject_books(i)\n",
    "        if  ISBN in diz_temp[1].keys():\n",
    "            return diz_temp[1][ISBN], i\n",
    "            \n",
    "def get_infos_from_title(title, index):\n",
    "    diz_temp = Ad_Scraper.get_subject_books(index)\n",
    "    author = diz_temp[0][title]['Autore']\n",
    "    year = diz_temp[0][title]['Anno']\n",
    "    abstract = diz_temp[0][title]['Abstract']\n",
    "    pages = diz_temp[0][title]['Pagine']\n",
    "    \n",
    "    return year, author, abstract, pages\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class Book():\n",
    "    def __init__(self,ISBN):\n",
    "        self.isbn = ISBN\n",
    "        [self.title, index] = get_title_from_ISBN(ISBN)\n",
    "        [year, author, abstract, pages] = get_infos_from_title(self.title, index)\n",
    "        self.print_year = year\n",
    "        self.author = author\n",
    "        self.abstract = abstract\n",
    "        self.pages = pages\n",
    "        self.category = Ad_Scraper.get_subject_list()[index]\n",
    "        self.index = index  #mi serve per risalire più velocemente alla categoria\n",
    "        \n",
    "    def abstract_len(self):\n",
    "        return len(self.abstract)\n",
    "        \n",
    "    def get_whole_price(self):\n",
    "        temp = Ad_Scraper.get_subject_books(self.index)[0] #accedo alle info relative (contenute nello scraper)\n",
    "        return temp[self.title]['Prezzo Originale']\n",
    "    \n",
    "    def get_net_price(self):\n",
    "        temp = Ad_Scraper.get_subject_books(self.index)[0] #accedo alle info relative (contenute nello scraper)\n",
    "        num = temp[self.title]['Sconto'].replace('%', '')\n",
    "        num = 1+float(num)/100  #percentuale di prezzo che dovrò pagare\n",
    "        return float(temp[self.title]['Prezzo Originale'])*num\n",
    "    \n",
    "    def print_book_infos(self):\n",
    "        print(\"Il libro intitolato\",self.title,\", lungo \",self.pages,\" pagine, dell'anno \",self.print_year,\", dell'autore \",self.author,\"può essere descritto dal seguente abstract: \\n\",self.abstract)\n",
    "        #non ho messo tutto ma l'idea è quella\n",
    "        \n",
    "tries = Book('9788845931536')\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.599999999999998"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tries.get_net_price()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVALXmT6meTC"
   },
   "source": [
    "# Creazione di una libreria digitale\n",
    "Richieste dell'esercizio:\n",
    "\n",
    "*   Implementare la classe `Book(ISBN)`: questa classe dovrà essere inizializzata soltanto dall'ISBN di un libro, utilizzando AdelphiScraper dovrà essere in grado di inizializzarsi con i seguenti attributi:\n",
    "    *   `self.ISBN` : ISBN del libro.\n",
    "    *   `self.title` : il titolo del libro.\n",
    "    *   `self.print_year` : l'anno dell'ultima ristampa.\n",
    "    *   `self.author` : l'autore del libro.\n",
    "    *   `self.abstract` : abstract del libro.\n",
    "    *   `self.pages` : numero di pagine del libro.\n",
    "    *   `self.category` : categoria a cui appartiene il libro.\n",
    "\n",
    "  **Suggerimento**: tutte queste informazioni devono essere reperite con varie chiamate ai metodi di AdelphiScraper e tramite trasformazioni alle strutture dati ricevute, si consiglia caldamente di chiamare AdelphiScraper esternamente e creare una struttura dati adeguata a cercare tutte le informazioni velocemente dato **soltanto** l'ISBN di un libro, a quel punto la classe Book potrà attingere da lì senza connettersi allo scraper in ogni sua istanza.\n",
    "\n",
    "  Dovrà inoltre possedere i seguenti metodi:\n",
    "    *   `get_whole_price(self)` : restituirà il prezzo lordo del libro usando AdelphiScraper.\n",
    "    *   `get_net_price(self)` : restituirà il prezzo netto del libro usando AdelphiScraper.\n",
    "    *   `print_book_infos(self)` : stamperà in output le varie informazioni sul libro.\n",
    "    *   `abstract_len` : restituisce lunghezza dell'abstract del libro\n",
    "\n",
    "* Vi è richiesto di digitalizzare le informazioni di alcuni libri, creare una classe chiamata `MyLibrary(ISBN_list)` che possa essere inizializzata soltanto con una lista di ISBN. In modo simile alla classe `Book(ISBN)` questa dovrà far uso di AdelphiScraper per collezionare le informazioni di tutti i libri in essa contenuti, si suggerisce l'utilizzo di dizionari e oggetti di tipo Book come strutture dati replicando gli stessi attributi e metodi (in questi ultimi si possa specificare il libro del quale siamo interessati al prezzo, all'abstract etc.).\n",
    "La classe dovrà inoltre avere i seguenti metodi:\n",
    "    * `insert_book(self, ISBN) `: inserisca nella libreria l'oggetto di tipo Book corrispondente all'ISBN passato.\n",
    "    * `remove_book(self, ISBN) `: rimuova dall libreria l'oggetto di tipo Book corrispondente all'ISBN passato.\n",
    "    * `get_library_value(self) `: restituirà il valore totale (dato dai prezzi) dei libri contenuti nella libreria, sia lordo che al netto degli sconti.\n",
    "    * `get_total_pages(self) ` : restituirà il numero totale di pagine dei libri nella nostra libreria\n",
    "    * `get_categories_number(self) ` : restituirà il numero di categorie differenti che sono presenti nella nostra libreria.\n",
    "\n",
    "* Introduciamo il concetto di libri \"vicini\": diciamo che due libri sono vicini se appartengono alla stessa categoria **oppure** il loro ISBN modulo 3 è lo stesso: se ad esempio due libri hanno come ISBN 134434**6** e ISBN 294823**9** questi avranno entrambi ISBN modulo 3 uguale a 0 e saranno vicini.\n",
    "    * Si inserisca nella classe `Book(ISBN)` il metodo `is_near(self, book_2)` che restituisca `True` se l'oggetto di tipo Book passato in input è vicino al libro rappresentato dall'oggetto Book che chiama il metodo, `False` altrimenti.\n",
    "```\n",
    "b1 = Book(123456)\n",
    "b2 = Book(123456789)\n",
    "b1.is_near(b2)\n",
    ">> True\n",
    "```\n",
    "    * Si inserisca nella classe `MyLibrary(ISBN_list)` il metodo `minimum_path(self, start_ISBN, end_ISBN) ` che riceve in input due ISBN appartenenti alla libreria, uno iniziale ed uno finale, e restituisca la lista ordinata degli ISBN dei libri facenti parte della libreria da cui bisogna passare per arrivare da quello iniziale a quello finale. Tuttavia, è possibile passare da un libro ad un altro solo se sono vicini, questa funzione deve restituire la sequenza di passaggi di lunghezza **più breve** per arrivare a destinazione.\n",
    "    * Si inserisca nella classe `MyLibrary(ISBN_list)` il metodo `minimum_cost_path(self, start_ISBN, end_ISBN) `, una versione alternativa del metodo precedente che invece che il cammino di lunghezza minore restituisce quello con il costo **netto** totale dei libri facenti parte del cammino minore possibile.\n",
    "\n",
    "Si usino i seguenti ISBN come caso prova delle varie implementazioni:\n",
    "\n",
    "Cose che potrebbero esservi utili: \n",
    "  * Attributi dei dizionari: .keys(), .values(), ...\n",
    "  * Teoria dei grafi\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNztnY58LrNzNTbzrZACDHp",
   "collapsed_sections": [],
   "name": "adelphi_scraping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
