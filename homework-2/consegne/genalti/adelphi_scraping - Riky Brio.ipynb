{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myLz0ycsuMMY"
   },
   "source": [
    "#Web scraping del sito della collana di libri Adelphi \n",
    "Una delle task più comuni per cui viene impiegato Python è il così detto **web scraping**. Il web scraping consiste nell'automatizzare l'ottenimento di alcune informazioni dal web tramite un codice e di utilizzarle di conseguenza. La qualità e la semplicità nell'ottenimento delle informazioni è dato solitamente dalla struttura della fonte: alcuni siti sono molto più semplici da navigare mentre altri possono essere più complessi. Per questo motivo il web scraping è spesso molto complesso. \n",
    "In questo esercizio vi verrà fornito uno scraper già fatto in grado di ottenere informazioni dal catalogo online della nota collana di **libri Adelphi** (https://www.adelphi.it/): calandovi nei panni di un avido lettore e collezionista di libri, il vostro obiettivo sarà di utilizzarlo per digitalizzare interamente la vostra collezione di libri, in modo da poter velocemente controllare l'inventario dei vostri libri ed alcune informazioni a riguardo con un semplice comando ogni volta che lo vorrete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "executionInfo": {
     "elapsed": 6465,
     "status": "ok",
     "timestamp": 1602763937339,
     "user": {
      "displayName": "Corso Python",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhUJnZlNXXV-eAoMnBindJd9r8g8VQoai18e-XA=s64",
      "userId": "02320948615677398231"
     },
     "user_tz": -120
    },
    "id": "D_37H-lC7lK3",
    "outputId": "aaa4db14-6f1b-46a4-e8c1-0bc34f97463b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\briol\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\briol\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\briol\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\briol\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\briol\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests) (2.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\briol\\appdata\\local\\programs\\python\\python38-32\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\briol\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\briol\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from beautifulsoup4) (2.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\briol\\appdata\\local\\programs\\python\\python38-32\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANTE\n",
    "# questa cella di codice serve ad installare nel vostro Python due tra i principali strumenti di web scraping: beautiful soup e requests.\n",
    "# qualora di fossero problemi con la loro installazione o import non esitate a contattarci\n",
    "!pip install requests\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DucKAxg-6g50"
   },
   "source": [
    "# Implementazione dello scraper\n",
    "Come anticipato, non vi sarà richiesto di implementare lo scraper. Tuttavia gli interessati possono trovare informazioni su come utilizzare al meglio le due librerie per lo scraping *requests* e *beautifulsoup* e cercare di comprendere il codice della classe AdelphiScraper. Se non siete tra questi potete saltare alla prossima sezione.\n",
    "Qui qualche risorsa:\n",
    "\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "https://requests.readthedocs.io/en/master/user/quickstart/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Gr5uChnzMN4a"
   },
   "outputs": [],
   "source": [
    "import requests as req\n",
    "import bs4 as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zUZulxHc7smv"
   },
   "outputs": [],
   "source": [
    "class AdelphiScraper():\n",
    "  def __init__(self):\n",
    "    self.catalog      = 'https://www.adelphi.it/catalogo/'\n",
    "    self.subject      = 'https://www.adelphi.it/catalogo/materia/'\n",
    "    self.subjects_map = self.init_subjects()\n",
    "\n",
    "  def init_subjects(self):\n",
    "    resp  = req.get(self.catalog)\n",
    "    soup  = bs.BeautifulSoup(resp.text, \"html.parser\")\n",
    "    items = soup.find_all('ul', class_='subject')\n",
    "    ret = dict()\n",
    "    for i in items:\n",
    "      for j in i:\n",
    "        ret.update({int(j.a['href'].split('/')[-1]) : j.text})\n",
    "    return ret\n",
    "\n",
    "  def get_subject_list(self):\n",
    "    return self.subjects_map\n",
    "  \n",
    "  def get_subject_books(self, subject_code):\n",
    "    page_found = True\n",
    "    suffix = ''\n",
    "    page_counter = 1\n",
    "    books = dict()\n",
    "    isbns = dict()\n",
    "    while page_found:\n",
    "      try:\n",
    "        resp = req.get(self.subject + str(subject_code) + suffix, allow_redirects = False)\n",
    "        soup = bs.BeautifulSoup(resp.text, \"html.parser\")\n",
    "        if not len(soup):\n",
    "          raise ValueError()\n",
    "        book_infos, isbn_maps = self.extract_books(soup)\n",
    "        books.update(book_infos)\n",
    "        isbns.update(isbn_maps)\n",
    "        page_counter += 1\n",
    "        suffix = '/p' + str(page_counter)\n",
    "      except:\n",
    "        page_found = False\n",
    "    return books, isbns\n",
    "\n",
    "  def extract_books(self, soup):\n",
    "    items = soup.find_all('div', class_='list_impressum')\n",
    "    items2 = soup.find_all('div', class_='data' )\n",
    "    items3 = soup.find_all('div', class_ = \"abstract hidden-xs\")\n",
    "    isbn_map  = dict()\n",
    "    book_info = dict()\n",
    "    counter = 0\n",
    "    for i in items:\n",
    "      isbn_map.update({i.a['href'].split('/')[-1] : i.a.text}) #isbn : titolo\n",
    "      book_info.update({i.a.text : {'Autore': i.div.text, \\\n",
    "                                    'Anno': items2[counter].text.split(' ')[0].split(',')[0], \\\n",
    "                                    'Prezzo Originale' : i.span.text.split(' ')[1].replace(',','.'), \\\n",
    "                                    'Sconto': i.span.text.split(' ')[2], \\\n",
    "                                    'Pagine' :items2[counter].text.split(' ')[2].split(',')[0].split('-')[-1], \\\n",
    "                                    'Abstract': items3[counter].text}})\n",
    "      counter += 1\n",
    "    return book_info, isbn_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwoSPBLFkHDm"
   },
   "source": [
    "#Utilizzo della classe AdelphiScraper\n",
    "\n",
    "*   La classe AdelphiScraper non richiede alcun argomento di inizializzazione.\n",
    "*   Essendo un WebScraper richiede ovviamente la connessione ad internet.\n",
    "*   Essa contiene al suo interno diversi attributi e metodi, i metodi che vi serviranno sono:\n",
    "    * `get_subject_list()` : questo metodo restituisce un dizionario contenente tutte le categorie della collana di libri Adelphi e il codice numerico a cui sono associate sul sito.\n",
    "    * `get_subject_books(category_code)` : questo metodo riceve il codice numerico (**come intero**) di una categoria e restituisce due dizionari: \n",
    "        * Il primo ha come chiave i titoli dei libri appartenenti alla categoria e come valori svariati dati ad essi inerenti (Autore, prezzo, anno di stampa dell'ultima edizione, etc.)\n",
    "        * Il secondo ha come chiavi gli ISBN (codice univoco diverso da libro a libro) e come valori i titoli dei libri associati.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TJl4Yq15njPs"
   },
   "outputs": [],
   "source": [
    "## Come prima cosa istanziate un oggetto di classe AdelphiScraper e provate ad utilizzare i due metodi sopra descritti per osservarne l'output,\n",
    "## questa operazione è molto importante al fine di capire bene quali sono le strutture dati a vostra dispozione.\n",
    "## ATTENZIONE : osservate bene quali sono i tipi dei dati contenuti nelle strutture che riceverete in output, più avanti avrete bisogno di farvi operazioni o conversioni.\n",
    "#ad=AdelphiScraper()\n",
    "#books,ISBN=ad.get_subject_books(3)\n",
    "#print(books)\n",
    "#print(ISBN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVALXmT6meTC"
   },
   "source": [
    "# Creazione di una libreria digitale\n",
    "Richieste dell'esercizio:\n",
    "\n",
    "*   Implementare la classe `Book(ISBN)`: questa classe dovrà essere inizializzata soltanto dall'ISBN di un libro, utilizzando AdelphiScraper dovrà essere in grado di inizializzarsi con i seguenti attributi:\n",
    "    *   `self.ISBN` : ISBN del libro.\n",
    "    *   `self.title` : il titolo del libro.\n",
    "    *   `self.print_year` : l'anno dell'ultima ristampa.\n",
    "    *   `self.author` : l'autore del libro.\n",
    "    *   `self.abstract` : abstract del libro.\n",
    "    *   `self.pages` : numero di pagine del libro.\n",
    "    *   `self.category` : categoria a cui appartiene il libro.\n",
    "\n",
    "  **Suggerimento**: tutte queste informazioni devono essere reperite con varie chiamate ai metodi di AdelphiScraper e tramite trasformazioni alle strutture dati ricevute, si consiglia caldamente di chiamare AdelphiScraper esternamente e creare una struttura dati adeguata a cercare tutte le informazioni velocemente dato **soltanto** l'ISBN di un libro, a quel punto la classe Book potrà attingere da lì senza connettersi allo scraper in ogni sua istanza.\n",
    "\n",
    "  Dovrà inoltre possedere i seguenti metodi:\n",
    "    *   `get_whole_price(self)` : restituirà il prezzo lordo del libro usando AdelphiScraper.\n",
    "    *   `get_net_price(self)` : restituirà il prezzo netto del libro usando AdelphiScraper.\n",
    "    *   `print_book_infos(self)` : stamperà in output le varie informazioni sul libro.\n",
    "    *   `abstract_len` : restituisce lunghezza dell'abstract del libro\n",
    "\n",
    "* Vi è richiesto di digitalizzare le informazioni di alcuni libri, creare una classe chiamata `MyLibrary(ISBN_list)` che possa essere inizializzata soltanto con una lista di ISBN. In modo simile alla classe `Book(ISBN)` questa dovrà far uso di AdelphiScraper per collezionare le informazioni di tutti i libri in essa contenuti, si suggerisce l'utilizzo di dizionari e oggetti di tipo Book come strutture dati replicando gli stessi attributi e metodi (in questi ultimi si possa specificare il libro del quale siamo interessati al prezzo, all'abstract etc.).\n",
    "La classe dovrà inoltre avere i seguenti metodi:\n",
    "    * `insert_book(self, ISBN) `: inserisca nella libreria l'oggetto di tipo Book corrispondente all'ISBN passato.\n",
    "    * `remove_book(self, ISBN) `: rimuova dall libreria l'oggetto di tipo Book corrispondente all'ISBN passato.\n",
    "    * `get_library_value(self) `: restituirà il valore totale (dato dai prezzi) dei libri contenuti nella libreria, sia lordo che al netto degli sconti.\n",
    "    * `get_total_pages(self) ` : restituirà il numero totale di pagine dei libri nella nostra libreria\n",
    "    * `get_categories_number(self) ` : restituirà il numero di categorie differenti che sono presenti nella nostra libreria.\n",
    "\n",
    "* Introduciamo il concetto di libri \"vicini\": diciamo che due libri sono vicini se appartengono alla stessa categoria **oppure** il loro ISBN modulo 3 è lo stesso: se ad esempio due libri hanno come ISBN 134434**6** e ISBN 294823**9** questi avranno entrambi ISBN modulo 3 uguale a 0 e saranno vicini.\n",
    "    * Si inserisca nella classe `Book(ISBN)` il metodo `is_near(self, book_2)` che restituisca `True` se l'oggetto di tipo Book passato in input è vicino al libro rappresentato dall'oggetto Book che chiama il metodo, `False` altrimenti.\n",
    "```\n",
    "b1 = Book(123456)\n",
    "b2 = Book(123456789)\n",
    "b1.is_near(b2)\n",
    ">> True\n",
    "```\n",
    "    * Si inserisca nella classe `MyLibrary(ISBN_list)` il metodo `minimum_path(self, start_ISBN, end_ISBN) ` che riceve in input due ISBN appartenenti alla libreria, uno iniziale ed uno finale, e restituisca la lista ordinata degli ISBN dei libri facenti parte della libreria da cui bisogna passare per arrivare da quello iniziale a quello finale. Tuttavia, è possibile passare da un libro ad un altro solo se sono vicini, questa funzione deve restituire la sequenza di passaggi di lunghezza **più breve** per arrivare a destinazione.\n",
    "    * Si inserisca nella classe `MyLibrary(ISBN_list)` il metodo `minimum_cost_path(self, start_ISBN, end_ISBN) `, una versione alternativa del metodo precedente che invece che il cammino di lunghezza minore restituisce quello con il costo **netto** totale dei libri facenti parte del cammino minore possibile.\n",
    "\n",
    "Si usino i seguenti ISBN come caso prova delle varie implementazioni:\n",
    "\n",
    "Cose che potrebbero esservi utili: \n",
    "  * Attributi dei dizionari: .keys(), .values(), ...\n",
    "  * Teoria dei grafi\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINISCO FUNZIONE AUSILIARIA\n",
    "\n",
    "def cerca_info(ISBN):\n",
    "    '''\n",
    "    La funzione scorre i libri categoria per categoria\n",
    "    servendosi del codice ISBN per identificae il libro scelto. \n",
    "    A questo punto, crea e ritorna un dizionario con le informazioni\n",
    "    che la classe successivamente usa\n",
    "    durante l'inizializzazione '''\n",
    "    \n",
    "    Ad_Scraper=AdelphiScraper()\n",
    "    keys=['title','print_year','author','abstract','pages','category'] #lista chiavi\n",
    "    values=[] #lista valori che agiorno proseguendo\n",
    "    categories=Ad_Scraper.get_subject_list()\n",
    "    len_categories=len(categories) ##trovo cardinalità delle categorie\n",
    "    i=0\n",
    "    is_in=False\n",
    "    while not is_in and i<len_categories:\n",
    "        i+=1\n",
    "        books,ISBN_dict=Ad_Scraper.get_subject_books(i) #tramite ISBN ho keys.Se c'è codice, posso estrarre nome e tutto resto a cascata\n",
    "        if str(ISBN) in ISBN_dict.keys():\n",
    "            is_in=True\n",
    "            num_category=i\n",
    "            title=ISBN_dict[str(ISBN)] #ora che ho titolo,da books sono in grado di estrarre tutte le altre informazioni\n",
    "            values.append(title)\n",
    "    values.append(books[title]['Anno']) #aggiungo anno pubblicazione ai values\n",
    "    values.append(books[title]['Autore']) #agiungo autore ai values\n",
    "    values.append(books[title]['Abstract']) #aggiugno descrizione ai values\n",
    "    values.append(books[title]['Pagine']) #aggiungo numero pagine ai values\n",
    "    values.append(categories[num_category]) #aggiungo categoria ai values\n",
    "    d={chiave:valore for (chiave,valore) in zip(keys,values)}\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9788845933950 Vite che non sono la mia 2019 Emmanuel Carrère «Da sei mesi a questa parte, ogni giorno, di mia spontanea volontà, passo alcune ore davanti al computer a scrivere di ciò che mi fa più paura al mondo: la morte di un figlio per i suoi genitori, quella di una giovane donna per i suoi figli e suo marito. La vita mi ha reso testimone di queste due sciagure, l’una dopo l’altra, e mi ha assegnato il compito, o almeno... 221 Autobiografie\n"
     ]
    }
   ],
   "source": [
    "## DEFINISCO LA NUOVA CLASSE BOOKS\n",
    "class Book():\n",
    "    \n",
    "    #FUNZIONE CHE INIZIALIZZA CLASSE\n",
    "    \n",
    "    def __init__(self,ISBN):\n",
    "        info=cerca_info(ISBN)\n",
    "        self.ISBN=ISBN\n",
    "        self.title=info['title']\n",
    "        self.print_year=info['print_year']\n",
    "        self.author=info['author']\n",
    "        self.abstract=info['abstract']\n",
    "        self.pages=info['pages']\n",
    "        self.category=info['category']\n",
    "    \n",
    "    #FUNZIONE CHE TROVA E RESTITUISCE IL PREZZO NON SCONTATO\n",
    "    \n",
    "    def get_whole_price(self):\n",
    "        ad=AdelphiScraper()\n",
    "        category_dict=ad.get_subject_list() #dizionario categorie-valori numerici\n",
    "        for chiave in category_dict.keys():\n",
    "            if category_dict[chiave]==self.category:\n",
    "                category_code=chiave #conoscendo la categoria, rintraccio il valore a cui è associata e blocco ciclo for\n",
    "                break\n",
    "        books_dict,ISBN_dict=ad.get_subject_books(int(category_code))\n",
    "        for titolo in books.keys():\n",
    "            if titolo==self.title:\n",
    "                return books[titolo]['Prezzo Originale']\n",
    "    \n",
    "    #FUNZIONE CHE TROVA E RESTITUISCE IL PREZZO SCONTATO\n",
    "    \n",
    "    def get_net_price(self):\n",
    "        ad=AdelphiScraper()\n",
    "        category_dict=ad.get_subject_list() #dizionario categorie-valori numerici\n",
    "        for chiave in category_dict.keys():\n",
    "            if category_dict[chiave]==self.category:\n",
    "                category_code=chiave #conoscendo la categoria, rintraccio il valore a cui è associata e blocco ciclo for\n",
    "                break\n",
    "        books_dict,ISBN_dict=ad.get_subject_books(int(category_code))\n",
    "        for titolo in books.keys():\n",
    "            if titolo==self.title:\n",
    "                total_price=float(books[titolo]['Prezzo Originale'])\n",
    "                sconto=int(books[titolo]['Sconto'][1:-1])\n",
    "                return total_price*(1-sconto/100)\n",
    "      \n",
    "    \n",
    "    #FUNZIONE CHE STAMPA LE INFORMAZIONI DELLA CLASSE\n",
    "    \n",
    "    def print_book_infos(self):\n",
    "        print(self.ISBN,self.title,self.print_year,self.author,self.abstract,self.pages,self.category)\n",
    "    \n",
    "    #FUNZIONE CHE STAMPA IL NUMERO DI PAROLE/SEGNI NELL'ABSTRACT\n",
    "    \n",
    "    def abstract_len(self):\n",
    "        testo=self.abstract.split(' ') #conto il numero di parole,segni\n",
    "        return len(testo)\n",
    "    \n",
    "    #FUNZIONE CHE TORNA TRUE SE LIBRI VICINI, FALSE ALTRIMENTI\n",
    "    \n",
    "    def is_near(self,books_2):\n",
    "        if self.category==books_2.category or (self.ISBN %3)==(books_2.ISBN%3):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "libro=Book(9788845933950)\n",
    "libro.print_book_infos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-2-da53a3721349>, line 70)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-da53a3721349>\"\u001b[1;36m, line \u001b[1;32m70\u001b[0m\n\u001b[1;33m    ISBN_list=[9788845934094,9788845933950]\u001b[0m\n\u001b[1;37m                                                       ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#CLASSE MYLIBRARY\n",
    "\n",
    "class MyLibrary():\n",
    "    \n",
    "    def __init__(self,ISBN_list):\n",
    "        self.books=[]\n",
    "        self.create(ISBN_list)\n",
    "    \n",
    "    #TALE FUNZIONE INIZIALIZZA LA LISTA DI ELEMENTI BOOKS IN LIBRERIA\n",
    "    \n",
    "    def create(self,ISBN_list):\n",
    "        for codice in ISBN_list: \n",
    "            new_book=Book(int(codice))\n",
    "            self.books.append(new_book)\n",
    "    \n",
    "    #TALE FUNZIONE INSERISCI UN NUOVO LIBRO NELLA LIBRERIA A PARTIRE DAL CODICE ISBN\n",
    "    \n",
    "    def insert_book(self,ISBN):\n",
    "        new_book=Book(ISBN)\n",
    "        self.books.append(new_book)\n",
    "        \n",
    "    #TALE FUNZIONE RIMUOVE UN LIBRO RESENTE NELLA LIBRERIA A PARTIRE DAL CODICE ISBN\n",
    "    \n",
    "    def remove_books(self,ISBN):\n",
    "        removed=False\n",
    "        index=-1\n",
    "        while not removed and index<len(self.books):\n",
    "            index+=1\n",
    "            if ISBN==self.books[index].ISBN:\n",
    "                self.books.pop(index)\n",
    "                removed=True\n",
    "    \n",
    "    #TALE FUNZIONA RITORNA LA SOMMA DEI PREZZI (LORDI,NETTI) DEI LIBRI DELLA LIBRERIA\n",
    "    \n",
    "    def get_library_value(self):\n",
    "        prezzo_lordo=0\n",
    "        prezzo_netto=0\n",
    "        for i in range(len(self.books)):\n",
    "            prezzo_lordo+=float(self.books[i].get_whole_price()) \n",
    "            prezzo_netto+=float(self.books[i].get_net_price())\n",
    "        return prezzo_lordo, prezzo_netto\n",
    "    \n",
    "    #TALE FUNZIONE RITORNA LA SOMMA DELLE PAGINE DEI LIBRI CONTENUTI NELLA LIBRERIA\n",
    "\n",
    "    def get_library_pages(self):\n",
    "        total_pages=0\n",
    "        for i in range(len(self.books)):\n",
    "            total_pages+=int(self.books[i].pages)\n",
    "        return total_pages\n",
    "    \n",
    "    #TALE FUNZIONE RITORNA IL NUMERO DI CATEGORIE A CUI APPARTENGONO I LIBRI DELLA LIBRERIA\n",
    "    \n",
    "    def get_categories_number(self):\n",
    "        category_list=[]\n",
    "        count=0\n",
    "        for i in range(len(self.books)):\n",
    "            if count==0 or self.books[i].category not in category_list:\n",
    "                count+=1\n",
    "                category_list.append(self.books[i].category)\n",
    "        return count\n",
    "\n",
    "\n",
    "ISBN_list=[9788845934094,9788845933950]            \n",
    "libreria=MyLibrary(ISBN_list) \n",
    "print(libreria.get_library_value(),libreria.get_library_pages(),libreria.get_categories_number())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNztnY58LrNzNTbzrZACDHp",
   "collapsed_sections": [],
   "name": "adelphi_scraping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
